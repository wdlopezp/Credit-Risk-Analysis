{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis Part 2: Feature Engineering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Libraries importing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from utils import model_evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# GLOBAL CONSTANTS\n",
    "SEED = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2436/3461338438.py:3: DtypeWarning: Columns (34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(os.path.join('./data',\n"
     ]
    }
   ],
   "source": [
    "# Read training data\n",
    "data_dir = os.listdir('./data')[-1]\n",
    "data = pd.read_csv(os.path.join('./data',\n",
    "                                data_dir,\n",
    "                                'preprocessed_data.csv'), index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    PAYMENT_DAY APPLICATION_SUBMISSION_TYPE  POSTAL_ADDRESS_TYPE SEX  \\\n0                                                                      \n1             5                         Web                    1   F   \n2            15                       Carga                    1   F   \n3             5                         Web                    1   F   \n4            20                         Web                    1   F   \n5            10                         Web                    1   M   \n6            10                         NaN                    1   M   \n7            15                       Carga                    1   F   \n8            25                         Web                    1   F   \n9            15                         NaN                    1   F   \n10            5                         NaN                    1   F   \n\n    MARITAL_STATUS  QUANT_DEPENDANTS STATE_OF_BIRTH  NACIONALITY  \\\n0                                                                  \n1              6.0                 1             RN            1   \n2              2.0                 0             RJ            1   \n3              2.0                 0             RN            1   \n4              2.0                 0             PE            1   \n5              2.0                 0             RJ            1   \n6              2.0                 0             MG            1   \n7              2.0                 2             BA            1   \n8              1.0                 0             MG            1   \n9              1.0                 0             SP            1   \n10             1.0                 0             RS            1   \n\n   RESIDENCIAL_STATE FLAG_RESIDENCIAL_PHONE  ... PROFESSIONAL_STATE  \\\n0                                            ...                      \n1                 RN                      Y  ...             NO_JOB   \n2                 RJ                      Y  ...             NO_JOB   \n3                 RN                      Y  ...             NO_JOB   \n4                 PE                      N  ...             NO_JOB   \n5                 RJ                      Y  ...             NO_JOB   \n6                 MG                      Y  ...                 MG   \n7                 BA                      Y  ...             NO_JOB   \n8                 SP                      N  ...                 SP   \n9                 SP                      Y  ...             NO_JOB   \n10                RS                      Y  ...                 RS   \n\n    FLAG_PROFESSIONAL_PHONE  PROFESSIONAL_PHONE_AREA_CODE  MONTHS_IN_THE_JOB  \\\n0                                                                              \n1                         N                       NO_DATA                  0   \n2                         N                       NO_DATA                  0   \n3                         N                       NO_DATA                  0   \n4                         N                       NO_DATA                  0   \n5                         N                       NO_DATA                  0   \n6                         N                       NO_DATA                  0   \n7                         N                       NO_DATA                  0   \n8                         Y                             5                  0   \n9                         N                       NO_DATA                  0   \n10                        Y                            54                  0   \n\n    PROFESSION_CODE  OCCUPATION_TYPE  PRODUCT  AGE  RESIDENCIAL_ZIP_3  \\\n0                                                                       \n1               9.0              4.0        1   32                595   \n2              11.0              4.0        1   34                230   \n3              11.0              NaN        1   27                591   \n4               NaN              NaN        1   61                545   \n5               9.0              5.0        1   48                235   \n6               9.0              2.0        2   40                371   \n7              11.0              4.0        1   40                413   \n8              11.0              2.0        1   28                686   \n9               0.0              2.0        2   31                172   \n10              9.0              2.0        1   41                914   \n\n    TARGET_LABEL_BAD=1  \n0                       \n1                    1  \n2                    1  \n3                    0  \n4                    0  \n5                    1  \n6                    1  \n7                    1  \n8                    0  \n9                    0  \n10                   0  \n\n[10 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PAYMENT_DAY</th>\n      <th>APPLICATION_SUBMISSION_TYPE</th>\n      <th>POSTAL_ADDRESS_TYPE</th>\n      <th>SEX</th>\n      <th>MARITAL_STATUS</th>\n      <th>QUANT_DEPENDANTS</th>\n      <th>STATE_OF_BIRTH</th>\n      <th>NACIONALITY</th>\n      <th>RESIDENCIAL_STATE</th>\n      <th>FLAG_RESIDENCIAL_PHONE</th>\n      <th>...</th>\n      <th>PROFESSIONAL_STATE</th>\n      <th>FLAG_PROFESSIONAL_PHONE</th>\n      <th>PROFESSIONAL_PHONE_AREA_CODE</th>\n      <th>MONTHS_IN_THE_JOB</th>\n      <th>PROFESSION_CODE</th>\n      <th>OCCUPATION_TYPE</th>\n      <th>PRODUCT</th>\n      <th>AGE</th>\n      <th>RESIDENCIAL_ZIP_3</th>\n      <th>TARGET_LABEL_BAD=1</th>\n    </tr>\n    <tr>\n      <th>0</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>Web</td>\n      <td>1</td>\n      <td>F</td>\n      <td>6.0</td>\n      <td>1</td>\n      <td>RN</td>\n      <td>1</td>\n      <td>RN</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>NO_JOB</td>\n      <td>N</td>\n      <td>NO_DATA</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>32</td>\n      <td>595</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>15</td>\n      <td>Carga</td>\n      <td>1</td>\n      <td>F</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>RJ</td>\n      <td>1</td>\n      <td>RJ</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>NO_JOB</td>\n      <td>N</td>\n      <td>NO_DATA</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>34</td>\n      <td>230</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>Web</td>\n      <td>1</td>\n      <td>F</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>RN</td>\n      <td>1</td>\n      <td>RN</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>NO_JOB</td>\n      <td>N</td>\n      <td>NO_DATA</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>27</td>\n      <td>591</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20</td>\n      <td>Web</td>\n      <td>1</td>\n      <td>F</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>PE</td>\n      <td>1</td>\n      <td>PE</td>\n      <td>N</td>\n      <td>...</td>\n      <td>NO_JOB</td>\n      <td>N</td>\n      <td>NO_DATA</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>61</td>\n      <td>545</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>10</td>\n      <td>Web</td>\n      <td>1</td>\n      <td>M</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>RJ</td>\n      <td>1</td>\n      <td>RJ</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>NO_JOB</td>\n      <td>N</td>\n      <td>NO_DATA</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>48</td>\n      <td>235</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>M</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>MG</td>\n      <td>1</td>\n      <td>MG</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>MG</td>\n      <td>N</td>\n      <td>NO_DATA</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>40</td>\n      <td>371</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>15</td>\n      <td>Carga</td>\n      <td>1</td>\n      <td>F</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>BA</td>\n      <td>1</td>\n      <td>BA</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>NO_JOB</td>\n      <td>N</td>\n      <td>NO_DATA</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>4.0</td>\n      <td>1</td>\n      <td>40</td>\n      <td>413</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>25</td>\n      <td>Web</td>\n      <td>1</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>MG</td>\n      <td>1</td>\n      <td>SP</td>\n      <td>N</td>\n      <td>...</td>\n      <td>SP</td>\n      <td>Y</td>\n      <td>5</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>28</td>\n      <td>686</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>15</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>SP</td>\n      <td>1</td>\n      <td>SP</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>NO_JOB</td>\n      <td>N</td>\n      <td>NO_DATA</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>31</td>\n      <td>172</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>F</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>RS</td>\n      <td>1</td>\n      <td>RS</td>\n      <td>Y</td>\n      <td>...</td>\n      <td>RS</td>\n      <td>Y</td>\n      <td>54</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>1</td>\n      <td>41</td>\n      <td>914</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 35 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look on data inside the training dataset\n",
    "data.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Read the numerical and categorical features txt files\n",
    "num_features = []\n",
    "with open('./numerical_features_names.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        # Read line by line and append top empty list\n",
    "        num_features.append(line.split('\\n')[0])\n",
    "\n",
    "cat_features = []\n",
    "with open('./categorical_features_names.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        # Read line by line and append top empty list\n",
    "        cat_features.append(line.split('\\n')[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Convert dtypes to the right ones\n",
    "# First use suggested dtypes from pandas core\n",
    "data = data.convert_dtypes()\n",
    "# Remove Target variable from features\n",
    "cat_features.remove('TARGET_LABEL_BAD=1')\n",
    "# Then use the lists generated before\n",
    "for col in cat_features:\n",
    "    # First to string\n",
    "    data[col] = data[col].astype('string')\n",
    "    data[col] = pd.Categorical(data[col])\n",
    "\n",
    "# As Pandas could introduce pd.NA values in some features\n",
    "# when converting them to categorical, let's replace them with np.nan by casting\n",
    "# int columns to float32\n",
    "cols_to_float = data.select_dtypes(include='int').columns\n",
    "data[cols_to_float] = data[cols_to_float].astype(dtype='float32')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##Dataset Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Split data into features and label\n",
    "X, y = data.drop(columns=['TARGET_LABEL_BAD=1']), data['TARGET_LABEL_BAD=1']\n",
    "# Split dataset into Train and Test\n",
    "X_train_0, X_test, y_train_0, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=SEED\n",
    ")\n",
    "# Split train datasets into train and validation datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_0, y_train_0, test_size=0.1, random_state=SEED\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "## Build processing pipeline\n",
    "# Create individual transformers\n",
    "num_transformer = Pipeline(\n",
    "        steps=[\n",
    "            ('imputer' , SimpleImputer(strategy='median')),\n",
    "            ('scaler'  , StandardScaler())\n",
    "        ]\n",
    ")\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "        steps=[\n",
    "            ('imputer2', SimpleImputer(missing_values=pd.NA,\n",
    "                                      strategy='most_frequent')),\n",
    "            ('encoder' , OneHotEncoder(drop='if_binary',\n",
    "                                       #dtype='int8',\n",
    "                                       handle_unknown='ignore',\n",
    "                                       sparse=False))\n",
    "        ]\n",
    ")\n",
    "\n",
    "# Ensemble all the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num' , num_transformer , num_features),\n",
    "            ('cat' , cat_transformer , cat_features)\n",
    "        ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w/AnyOne_AI/cohort-02-2022/Final_Project/Credit-Risk-Analysis/FP_env/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [16, 19] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/home/w/AnyOne_AI/cohort-02-2022/Final_Project/Credit-Risk-Analysis/FP_env/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [16, 19] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/home/w/AnyOne_AI/cohort-02-2022/Final_Project/Credit-Risk-Analysis/FP_env/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:188: UserWarning: Found unknown categories in columns [4, 16, 19] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Use ColumnTransformer 'preprocessor' to process data\n",
    "# Train data\n",
    "X_train_pre   = preprocessor.fit_transform(X=X_train)\n",
    "X_train_0_pre = preprocessor.transform(X=X_train_0)\n",
    "# Validation data\n",
    "X_val_pre = preprocessor.transform(X=X_val)\n",
    "# Test data\n",
    "X_test_pre = preprocessor.transform(X=X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save all datasets\n",
    "np.savetxt(os.path.join('./data',\n",
    "                        data_dir,\n",
    "                        'X_train.csv'), X_train_pre, delimiter=',')\n",
    "np.savetxt(os.path.join('./data',\n",
    "                        data_dir,\n",
    "                        'X_val.csv'), X_val_pre, delimiter=',')\n",
    "np.savetxt(os.path.join('./data',\n",
    "                        data_dir,\n",
    "                        'X_test.csv'), X_test_pre, delimiter=',')\n",
    "np.savetxt(os.path.join('./data',\n",
    "                        data_dir,\n",
    "                        'y_train.csv'), y_train, delimiter=',')\n",
    "np.savetxt(os.path.join('./data',\n",
    "                        data_dir,\n",
    "                        'y_val.csv'), y_val, delimiter=',')\n",
    "np.savetxt(os.path.join('./data',\n",
    "                        data_dir,\n",
    "                        'y_test.csv'), y_test, delimiter=',')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Save features names after preprocessing\n",
    "pd.Series(preprocessor.get_feature_names_out()).to_csv(\n",
    "        os.path.join('./data',\n",
    "                     data_dir,\n",
    "                     'features_names_out.csv')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
